{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 — Generate CSV using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV generated successfully: listings.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR API KEY\"\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://openai.vocareum.com/v1\"\n",
    "\n",
    "openai.api_key = \"YOUR API KEY\"\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "Generate 10 synthetic real estate listings.\n",
    "Return ONLY valid CSV format (no backticks, no commentary).\n",
    "Columns:\n",
    "Neighborhood,Price,Bedrooms,Bathrooms,House Size,Description\n",
    "\n",
    "Rules:\n",
    "- Bedrooms must be an integer between 1 and 5.\n",
    "- Bathrooms must be an integer between 1 and 4.\n",
    "- Price must be a realistic positive number.\n",
    "- House Size must be a positive number in square feet.\n",
    "- Add a proper in detail description for each estate.\n",
    "- There should not be any None/Null/Void Cell in the CSV\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.5\n",
    ")\n",
    "\n",
    "csv_text = response.choices[0].message.content.strip()\n",
    "\n",
    "# Save directly as CSV file\n",
    "with open(\"listings.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(csv_text)\n",
    "\n",
    "print(\"CSV generated successfully: listings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 — Load CSV → Split → Embed → ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load CSV\n",
    "loader = CSVLoader(file_path=\"listings.csv\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split long descriptions if needed\n",
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "\n",
    "# Embeddings + ChromaDB\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(split_docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3 — Semantic Search (Using ChromaDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Result 1 ---\n",
      "Neighborhood: Suburbia\n",
      "Price: 750000\n",
      "Bedrooms: 4\n",
      "Bathrooms: 2\n",
      "House Size: 2500\n",
      "Description: Spacious 4 bedroom, 2 bathroom family home in a quiet suburban neighborhood. Large backyard perfect for kids and pets.\n",
      "\n",
      "--- Result 2 ---\n",
      "Neighborhood: Historic District\n",
      "Price: 950000\n",
      "Bedrooms: 3\n",
      "Bathrooms: 2\n",
      "House Size: 2200\n",
      "Description: Quaint 3 bedroom, 2 bathroom historic home in a charming neighborhood. Close to shops, restaurants, and cultural attractions.\n",
      "\n",
      "--- Result 3 ---\n",
      "Neighborhood: Beachfront\n",
      "Price: 1000000\n",
      "Bedrooms: 3\n",
      "Bathrooms: 3\n",
      "House Size: 1800\n",
      "Description: Beautiful 3 bedroom, 3 bathroom beachfront villa with stunning ocean views. Ideal for those who love to relax by the water.\n",
      "\n",
      "--- Result 4 ---\n",
      "Neighborhood: Lakeview\n",
      "Price: 800000\n",
      "Bedrooms: 5\n",
      "Bathrooms: 4\n",
      "House Size: 3000\n",
      "Description: Spacious 5 bedroom, 4 bathroom lakefront home with panoramic views. Ideal for large families or those who love to entertain.\n",
      "\n",
      "--- Result 5 ---\n",
      "Neighborhood: City Center\n",
      "Price: 900000\n",
      "Bedrooms: 2\n",
      "Bathrooms: 2\n",
      "House Size: 1500\n",
      "Description: Modern 2 bedroom, 2 bathroom apartment in the bustling city center. Close to shopping, dining, and public transportation.\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# SEMANTIC SEARCH QUERY\n",
    "query = \"Find me a 3-bedroom house near a family-friendly neighborhood.\"\n",
    "\n",
    "# Retrieve top 5 similar documents\n",
    "results = db.similarity_search(query, k=5)\n",
    "\n",
    "for i, r in enumerate(results, 1):\n",
    "    print(f\"\\n--- Result {i} ---\")\n",
    "    print(r.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4 — Personalisation using RAG (Retrieval-Augmented Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best listing for a young working couple who need 2 bedrooms and a safe area would be the cozy 2 bedroom, 1 bathroom condo in the heart of downtown. It is in a safe neighborhood and perfect for young professionals.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# LLM\n",
    "llm = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Build Retriever\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# RAG Chain\n",
    "rag = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "query = \"Recommend the best listing for a young working couple who need 2 bedrooms and a safe area.\"\n",
    "response = rag.run(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5 - Add Personalization with ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ChatMessageHistory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== USER PREFERENCE SUMMARY ===\n",
      "Summarize user preferences clearly. Extract budget, bedrooms, amenities, and neighborhood type.\n",
      "\n",
      "\n",
      "=== FINAL RECOMMENDATION ===\n",
      "Based on your preferences for a quiet suburban neighborhood with 4 bedrooms and 2 bathrooms, I would recommend the property in Suburbia. It fits within your budget and offers a spacious family home with a large backyard, perfect for kids and pets. The Beachfront property may also be a good option with 3 bedrooms and 3 bathrooms, ideal for relaxation by the water. However, if you prefer a historic charm and close proximity to shops and restaurants, the property in the Historic District could be a great fit. Ultimately, the choice depends on your lifestyle and priorities. Let me know if you need more information or assistance in making your decision.\n"
     ]
    }
   ],
   "source": [
    "personal_questions = [\n",
    "    \"What is your ideal number of bedrooms?\",\n",
    "    \"What kind of neighborhood do you prefer?\",\n",
    "    \"What is your maximum budget?\",\n",
    "    \"Which amenities matter most to you?\",\n",
    "    \"Do you prefer urban, suburban, or semi-urban areas?\"\n",
    "]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 2. Hard-Coded Answers (replace with anything you like)\n",
    "# ---------------------------------------------\n",
    "answers = [\n",
    "    \"I want 3 bedrooms.\",\n",
    "    \"A quiet and family-friendly neighborhood.\",\n",
    "    \"My maximum budget is 80 lakhs.\",\n",
    "    \"I need parking, nearby schools, and a park.\",\n",
    "    \"I prefer suburban areas.\"\n",
    "]\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "# Initial system instruction\n",
    "history.add_user_message(\n",
    "    f\"You are a real estate AI assistant. Ask the user {len(personal_questions)} personalization questions.\"\n",
    ")\n",
    "\n",
    "# Add each Q/A pair into the chat history (simulated conversation)\n",
    "for q, a in zip(personal_questions, answers):\n",
    "    history.add_ai_message(q)     # AI asks the question\n",
    "    history.add_user_message(a)   # Hardcoded user answer\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 3. Create Summarization Memory\n",
    "# ---------------------------------------------\n",
    "llm_summary = OpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm_summary,\n",
    "    chat_memory=history,\n",
    "    memory_key=\"summary\",\n",
    "    input_key=\"question\",\n",
    "    return_messages=True,\n",
    "    buffer=\"Summarize user preferences clearly. Extract budget, bedrooms, amenities, and neighborhood type.\"\n",
    ")\n",
    "\n",
    "# Generate summary\n",
    "memory.load_memory_variables({\"question\": \"Summarize my home preferences.\"})\n",
    "summary_text = memory.buffer\n",
    "\n",
    "print(\"\\n\\n=== USER PREFERENCE SUMMARY ===\")\n",
    "print(summary_text)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 4. Personalized Prompt Template for RAG\n",
    "# ---------------------------------------------\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a smart real estate advisor.\n",
    "\n",
    "User Preferences Summary:\n",
    "{summary}\n",
    "\n",
    "Retrieved Property Information:\n",
    "{context}\n",
    "\n",
    "User Question:\n",
    "{question}\n",
    "\n",
    "Answer in a friendly, helpful tone (max 5 sentences).\n",
    "\"\"\",\n",
    "    input_variables=[\"summary\", \"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 5. Build final Personalized RAG system\n",
    "# ---------------------------------------------\n",
    "personalized_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, max_tokens=400),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    combine_docs_chain_kwargs=chain_type_kwargs,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# ---------------------------------------------\n",
    "# 6. Final Query (House Recommendation)\n",
    "# ---------------------------------------------\n",
    "final_query = \"Recommend the most suitable house for me based on my preferences.\"\n",
    "\n",
    "response = personalized_chain({\"question\": final_query,\n",
    "                             \"chat_history\":[]})\n",
    "\n",
    "print(\"\\n\\n=== FINAL RECOMMENDATION ===\")\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
